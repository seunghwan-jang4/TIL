{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gTMB8iPCA9o","executionInfo":{"status":"ok","timestamp":1730771710372,"user_tz":-540,"elapsed":19666,"user":{"displayName":"천준석","userId":"01372029356312389121"}},"outputId":"ab983e83-c40e-498f-f662-1d3f077f3b32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 목차\n","- 기본 용어 정리\n","  - Prompt, Role, Response\n","- ChatGPT 간단한 원리\n","  - LLM Next Token Prediction\n","- OpenAI API 호출 방법\n","  - Model, Prompt Text, Temperature\n","  - Max Length\n","- 몇 가지 기본 규칙들"],"metadata":{"id":"ZoOtWOQ7BgY7"}},{"cell_type":"markdown","source":["## 기본 용어 정리\n","\n","- Prompt: ChatGPT의 출력을 원하는 방향으로 유도하기 위한 입력 텍스트. Prompt는 보통 질문 또는 지시 형태를 나타냄\n","\n","| Role | Prompt |\n","| --- | --- |\n","| User | 왜 하늘은 하늘색인가요? |\n","\n","- Role: 역할. 크게는 (1) 사용자를 뜻하는 User (2) ChatGPT를 뜻하는 Assistant 그리고 (3) System이 존재\n","  - System은 사용자 Prompt 이전에 입력하는 성능 개선 용도의 Prompt\n","\n","| Role | Prompt |\n","| --- | --- |\n","| Assistant | 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 흡수하고 산란시키기 때문입니다. 태양으로부터 오는 빛은 다양한 색상을 가지고 있는데, 대기 중의 분자들은 파란색 빛을 더 많이 흡수하고 산란시키기 때문에 하늘은 파란색으로 보이게 됩니다. 이러한 현상을 레이리 산란이라고 합니다. 따라서 하늘은 하늘색으로 보이는 것입니다. |\n","\n","- Response (또는 Output): 사용자의 Prompt에 대한 LLM의 출력값"],"metadata":{"id":"Xv_vSllPCSAu"}},{"cell_type":"markdown","source":["## 간단한 원리 설명 - ChatGPT가 말을 하는 방식에 대하여\n","\n","- Next Token Prediction\n","- ChatGPT 같은 Large Language Model(LLM) 또는 대규모 언어 모델들은 기본적으로 정해진 수의 단어들을 알고 있습니다.\n","  - 예를 들어 메타의 라마2 7B는 32000개, 구글의 젬마 7B는 256000개를 알고 있습니다. (단어를 더 많이 안다고 성능이 좋아지는 것은 아닙니다)\n","- ChatGPT가 예를 들어 10만개의 단어를 알고 있다고 했을 때, 10만개 단어 중 다음 1개의 단어를 예측하는 방식입니다.\n","  - 예시 1. 왜 하늘은 하늘색인가요? ___\n","  - 예시 2. 왜 하늘은 하늘색인가요? 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 ___\n","- \"단어\"란 우리가 생각하는 단어는 아닙니다. ChatGPT는 한글이나 영어 문자를 바로 보는게 아니고 이걸 AI모델이 이해 할 수 있는 숫자들로 변환해야하는데 이 숫자들의 수입니다.\n","  - 공식 명칭은 tokens라고 합니다. platform.openai.com/tokenizer 웹사이트에서 tokenizer 기억 나시죠?"],"metadata":{"id":"6gLLd6LmNsgq"}},{"cell_type":"markdown","source":["## Google Colab에 OpenAI API Key 등록\n","- 왼쪽 열쇠 모양 버튼 클릭 (보안 비밀 / Secrets 메뉴)\n","- 이름에는 OPENAI_API_KEY 입력\n","- 값에는 OpenAI API Key 복붙하기"],"metadata":{"id":"0uP7QwHNNzvg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EHb7DUUJAd3v"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"TN4lgz6fBgBj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## OpenAI API 호출 방법\n","- OpenAI API 호출 방법이지만 다른 많은 LLM API들도 OpenAI API 형식을 동일하게 따르거나 비슷한 방식의 구조를 채택했습니다."],"metadata":{"id":"aLJowa9SOHQ_"}},{"cell_type":"code","source":[],"metadata":{"id":"2p0vjFKSBgHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IHqLNejSBgJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 한 개씩 살펴보기\n","- model: GPT 3.5, GPT-4 버전 별로 선택하실 수 있으며, 보통 더 좋은 성능의 모델일 수록 가격도 그만큼 비싼 편입니다.\n","- messages: Prompt, Role, Response/Output\n","- temperature: 높을 수록 동일한 Prompt에도 매번 다르게 이야기하는 경향이 강해집니다. 0.0으로 셋팅 시 같은 답변으로만 대답합니다.\n"],"metadata":{"id":"Dsu0lq4UO5my"}},{"cell_type":"markdown","source":["### OpenAI API 결과 조금 더 자세히 살펴보기"],"metadata":{"id":"dmUShXd3PMWK"}},{"cell_type":"code","source":[],"metadata":{"id":"QLqMVJO1BgMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 호출 시 지정하진 않지만 알아야 하는 내용\n","- max length / context window\n","  - 모델마다 입력 및 출력 최대 길이가 다르며, 보통 각 모델 소개 페이지에서 찾을 수 있습니다.\n","  - OpenAI API의 경우 입력 최대 길이 확인: https://platform.openai.com/tokenizer\n","    - 모델 별로 tokenizer는 다릅니다. \"왜 하늘은 하늘색인가요?\" 문장이 어떤 모델한테는 14토큰, 어떤 모델은 29토큰 일 수 있습니다."],"metadata":{"id":"5VbftcgyPTtg"}},{"cell_type":"markdown","source":["### 기본적인 Prompt 구조\n","\n","Prompt에는 2가지 종류가 존재\n","1. 사용자가 ChatGPT한테 실제로 전달하는 Prompt = User Prompt\n","2. 사용자 Prompt 이전에 오는 해당 LLM 어플리케이션에 적합한 메타 Prompt = System Prompt\n","\n","System Prompt란?\n","- 사용자 Prompt를 전달하기 전에 관련 맥락이나 지침을 설정하는 Prompt\n","  - 페르소나, 어조 등도 설정 할 수 있음\n","- System Prompt 예시\n","  - 출력값 지정 (ex. JSON Formatting)\n","  - 페르소나 및 어조 설정\n","  - 외부 정보 주입\n","  - 모델이 지켜야 할 규칙들 설정\n","\n","왠만한 모델들은 Prompt 입력 시 기본 System Prompt가 붙어있습니다. ChatGPT도 그렇습니다!"],"metadata":{"id":"lTyfp04OPXLz"}},{"cell_type":"code","source":[],"metadata":{"id":"w7me9UXVBgOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ynNEcxH7QWWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uxzw9L8KQWYt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Completion 말고 Stream도 살펴보기\n","- ChatGPT가 문장을 모두 완성하지 않고 각 단어 별로 완성되는데로 바로바로 보여주는 방법입니다."],"metadata":{"id":"qEMYTWbXQ_5D"}},{"cell_type":"code","source":[],"metadata":{"id":"KcF8CoNsQWau"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 몇 가지 기본 규칙들\n","\n","1. Prompt는 영어로 해야 모델의 제성능을 발휘하는 편\n","   - ChatGPT, Claude 같은 모델들의 학습 데이터 중 큰 비중이 영어로 추정되기 때문\n","   - 학습 데이터가 공개된 라마1의 경우에도 대부분이 영어이며 한글은 극소량만 존재함\n","   - 한글 출력값이 필요하더라도 영어 Prompt를 통해 한글 출력값을 유도하는게 성능이 더 좋을 수 있음\n","2. AI 모델의 출력값은 입력값에 의존도가 매우 높음\n","   - 잘 한 것 같은데 원하는 결과가 안 나오면 입력이 모호하거나 필요한 내용이 빠졌을 수도 있음 (그게 아닌 경우 모델한테 태스크가 너무 어려울 수는 있음)\n","3. Prompt를 이렇게 저렇게 바꿨을 때 \"더 좋아보이는\" 결과보다는 특정 지표에서 유의미하게 더 좋거나 여러 번의 블라인드 테스팅을 통해 더 좋은 Prompt를 정하는 것을 추천\n","   - 다음 챕터인 프롬프트 엔지니어링 라이프사이클에서 자세하게 알려드릴 예정"],"metadata":{"id":"VXyg6BEmRvVO"}},{"cell_type":"markdown","source":["## 정리\n","- Prompt, Role, Output\n","  - Role은 User, Assistant(ex. ChatGPT)\n","  - Prompt는 User, System Prompt\n","- ChatGPT 작동 원리 = Next Token Prediction\n","  - ChatGPT 같은 모든 LLM API는 단어1, 단어2, 단어3이 있을 때 단어3 뒤에 나올 가장 적합한 단어를 선택하는 식으로 출력\n","- OpenAI API 호출 시 model과 messages를 지정해줘야 하며 결과 재현을 위해서는 temperature=0.0 지정을 추천\n","  - 전체 결과값을 한꺼번에 받는 Completions, 실시간으로 바로바로 받을 수 있는 Stream으로 나뉨"],"metadata":{"id":"_Wajst0DR7U1"}}]}